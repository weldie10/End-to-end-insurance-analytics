# End-to-End Insurance Risk Analytics & Predictive Modeling
## Project Report

**AlphaCare Insurance Solutions (ACIS)**  
**Date**: December 2025  
**Data Period**: February 2014 - August 2015  
**Status**: Task 1 & 2 Completed | Task 3 In Progress

---

## Executive Summary

This project develops a comprehensive risk analytics and predictive modeling platform for car insurance in South Africa. Through analysis of 1,000,098 historical claim records, we identify low-risk segments, optimize premium pricing, and enable data-driven marketing strategies to attract new clients while maintaining profitability.

**Key Achievements**:
- âœ… Established complete development infrastructure (Git, DVC, CI/CD)
- âœ… Built modular OOP architecture for scalable analysis
- âœ… Generated 5 key visualizations revealing risk patterns
- âœ… Identified significant risk variations across provinces and vehicle types
- ðŸ”„ Statistical hypothesis testing in progress
- ðŸ“‹ Machine learning models planned

---

## 1. Project Objective

**Primary Objective**: Analyze historical insurance claim data to identify low-risk customer segments and develop predictive models that enable AlphaCare Insurance Solutions to optimize premium pricing, reduce risk exposure, and attract new clients through targeted marketing strategies.

**Specific Objectives**:
1. **Risk Segmentation**: Identify low-risk segments (by province, zipcode, vehicle type, gender) for premium reduction opportunities
2. **Premium Optimization**: Develop ML models to predict optimal premium values based on car features, owner characteristics, and location
3. **Marketing Strategy**: Enable data-driven marketing to low-risk segments with competitive pricing
4. **Profitability Analysis**: Understand risk and margin differences through statistical hypothesis testing
5. **Predictive Modeling**: Build models predicting total claims by zipcode and optimal premium values

**Success Criteria**:
- Identify at least 3 low-risk segments with loss ratio < 40%
- Develop predictive models with RÂ² > 0.7 for premium prediction
- Complete hypothesis testing for all specified dimensions
- Generate comprehensive visualizations supporting business decisions

---

## 2. Data Overview

**Data Source**: Historical insurance claim data  
**Format**: Pipe-delimited text file (`MachineLearningRating_v3.txt`)  
**Records**: 1,000,098 transactions  
**Period**: February 2014 - August 2015 (18 months)

**Key Variables**:
- **Policy**: PolicyID, TransactionMonth, UnderwrittenCoverID
- **Client**: Gender, MaritalStatus, Province, PostalCode, Language, Bank
- **Vehicle**: Make, Model, VehicleType, RegistrationYear, Cylinders, CubicCapacity, Kilowatts
- **Financial**: TotalPremium, TotalClaims, SumInsured, CalculatedPremiumPerTerm
- **Coverage**: CoverType, CoverCategory, CoverGroup, Section, Product

**Data Quality**: 
- Missing values handled through preprocessing pipeline
- Outliers identified and documented
- Data types properly converted (dates, numeric, categorical)

---

## 3. Methodology

### 3.1 Analysis Framework

**Phase 1: Exploratory Data Analysis (EDA)** âœ… Completed
- Descriptive statistics and data quality assessment
- Loss ratio analysis by key dimensions (Province, VehicleType, Gender)
- Outlier detection and treatment
- Temporal trend analysis (18-month period)
- Vehicle make/model risk profiling

**Phase 2: Statistical Hypothesis Testing** ðŸ”„ In Progress
- Test risk differences across provinces (ANOVA/Kruskal-Wallis)
- Test risk differences between zipcodes
- Test margin (profit) differences between zipcodes
- Test risk differences between genders (Mann-Whitney U)

**Phase 3: Predictive Modeling** ðŸ“‹ Planned
- Linear regression models by zipcode for claims prediction
- Machine learning models for premium optimization (Random Forest, Gradient Boosting)
- Feature importance analysis
- Model evaluation and validation

### 3.2 Technical Stack

- **Architecture**: Object-Oriented Programming (OOP) with modular design
- **Data Processing**: Pandas, NumPy
- **Statistical Analysis**: SciPy, Statsmodels
- **Machine Learning**: Scikit-learn
- **Visualization**: Matplotlib, Seaborn
- **Data Version Control**: DVC
- **Development**: Python 3.8+, Jupyter Notebooks

---

## 4. Implementation Progress

### Task 1: Git and GitHub Setup âœ… COMPLETED

**Deliverables**:
- [x] Git repository initialized with proper version control
- [x] Comprehensive README with project overview
- [x] Modular OOP code structure implemented
- [x] GitHub Actions CI/CD workflow configured
- [x] Task-specific branches created (main, task-1, task-2)
- [x] Pull request workflow established

**Priority Breakdown**:

| Priority | Component | Description | Status |
|----------|-----------|-------------|--------|
| **P0 (Critical)** | Repository Initialization | Initialize git repository with proper structure | âœ… Completed |
| **P0 (Critical)** | .gitignore Configuration | Exclude venv, cache, data files, and sensitive information | âœ… Completed |
| **P1 (High)** | Branch Strategy | Create main, task-1, task-2 branches | âœ… Completed |
| **P1 (High)** | README.md | Comprehensive project documentation | âœ… Completed |
| **P1 (High)** | Project Structure | Modular OOP architecture | âœ… Completed |
| **P2 (Medium)** | CI/CD Workflow | Automated linting and testing pipeline | âœ… Completed |
| **P2 (Medium)** | PR Template | Standardized pull request template | âœ… Completed |

### Task 2: Data Version Control (DVC) âœ… COMPLETED

**Deliverables**:
- [x] DVC initialized in repository
- [x] Local remote storage configured (`data_storage/`)
- [x] Data file tracked with DVC (`MachineLearningRating_v3.txt`)
- [x] DVC artifacts committed with proper .gitignore rules
- [x] Data versioning workflow established

**Key Achievements**:
- Large data file (505 MB) properly versioned without committing to git
- DVC tracking file (`MachineLearningRating_v3.txt.dvc`) committed
- Reproducible data pipeline established

### Task 3: Exploratory Data Analysis & Statistics ðŸ”„ IN PROGRESS

**Current Status**:
- [x] Data loading and preprocessing pipeline
- [x] Loss ratio calculations by multiple dimensions
- [x] Temporal trend analysis
- [x] Vehicle make/model analysis
- [x] Five key visualizations generated
- [ ] Statistical hypothesis testing (in progress)
- [ ] Additional visualizations (12 remaining)

**Next Steps**:
1. Complete hypothesis testing for all dimensions
2. Generate remaining visualizations
3. Document statistical findings

### Task 4: Machine Learning & Predictive Modeling ðŸ“‹ PLANNED

**Planned Deliverables**:
- [ ] Linear regression models by zipcode
- [ ] Premium prediction ML models
- [ ] Feature importance analysis
- [ ] Model evaluation and validation
- [ ] Model performance visualizations

---

## 5. Results & Key Findings

### 5.1 Portfolio-Level Insights

- **Overall Loss Ratio**: Calculated and monitored as primary KPI across all dimensions
- **Temporal Patterns**: Identified seasonal and monthly trends in claims and premiums over 18-month period
- **Distribution Characteristics**: Understood claim frequency and premium distributions (log-normal patterns observed)

### 5.2 Geographic Insights

- **Province Risk Variation**: Significant differences in loss ratios across provinces
  - Low-risk provinces (< 40% loss ratio): Opportunities for premium reduction and market expansion
  - High-risk provinces (> 60% loss ratio): Require premium adjustments and enhanced risk management
- **Geographic Segmentation**: Clear risk clusters identified for targeted marketing

### 5.3 Vehicle Insights

- **Vehicle Type Risk**: Clear differentiation in risk profiles across vehicle types
- **Make-Specific Risk**: Significant variation in risk by vehicle manufacturer
  - Top 10 makes by claims volume identified
  - Top 10 makes by loss ratio (highest risk) identified
- **Pricing Efficiency**: Opportunities to optimize premium-to-risk ratios for specific vehicle segments

### 5.4 Temporal Insights

- **Seasonal Patterns**: Identified periods of increased risk requiring enhanced risk management
- **Trend Analysis**: Portfolio performance trends tracked over 18-month period
- **Risk Threshold Monitoring**: Visual tracking of portfolio health against 40% and 60% benchmarks

---

## 6. Generated Visualizations

### 6.1 Portfolio Overview Dashboard
**File**: `reports/visualizations/01_portfolio_overview.png`

**Components**: Overall Loss Ratio KPI, Monthly Premium vs Claims trends, Claim frequency distribution, Premium distribution box plot

**Key Insight**: High-level portfolio health metrics showing temporal patterns and distribution characteristics.

---

### 6.2 Loss Ratio by Province
**File**: `reports/visualizations/03_loss_ratio_province.png`

**Visualization**: Horizontal bar chart with color-coded risk levels (Red: >60%, Orange: 40-60%, Green: <40%)

**Key Insight**: Identifies provinces with highest and lowest risk profiles, enabling targeted marketing and premium adjustments.

**Business Action**: Consider premium reductions in green provinces, premium increases in red provinces.

---

### 6.3 Loss Ratio by Vehicle Type
**File**: `reports/visualizations/04_loss_ratio_vehicle_type.png`

**Components**: Top 10 vehicle types by loss ratio, Premium vs Claims scatter plot

**Key Insight**: Identifies vehicle types with highest risk profiles and reveals pricing efficiency.

**Business Action**: Adjust premiums for high-risk vehicle types, develop specialized products for low-risk segments.

---

### 6.4 Temporal Trends Analysis
**File**: `reports/visualizations/07_temporal_trends.png`

**Components**: Monthly Premium and Claims trends (dual-axis), Monthly Loss Ratio trend with risk thresholds

**Key Insight**: Reveals seasonal patterns and portfolio performance trends over time.

**Business Action**: Implement seasonal pricing adjustments, enhance risk management during high-risk periods.

---

### 6.5 Vehicle Make Analysis
**File**: `reports/visualizations/09_vehicle_make_analysis.png`

**Components**: Top 10 makes by total claims, Top 10 makes by loss ratio (highest risk)

**Key Insight**: Identifies vehicle makes with highest claim volumes and worst loss ratios.

**Business Action**: Develop partnerships with low-risk manufacturers, adjust premiums based on make risk profiles.

---

## 7. Technical Architecture

### 7.1 Object-Oriented Design

```
src/alphacare/
â”œâ”€â”€ data/              # DataLoader: Data loading and preprocessing
â”œâ”€â”€ eda/               # EDAAnalyzer: Exploratory data analysis
â”œâ”€â”€ statistics/        # HypothesisTester: Statistical testing
â”œâ”€â”€ models/            # ModelTrainer, LinearRegressionModel: ML models
â””â”€â”€ utils/             # Logging, DVC management utilities
```

### 7.2 Key Features

- **Modular Design**: Each component is a separate, reusable class
- **Data Version Control**: DVC integration for reproducible pipelines
- **Comprehensive Logging**: Full logging throughout the pipeline
- **Error Handling**: Robust error handling and validation
- **Extensible**: Easy to add new analysis methods and visualizations

### 7.3 Code Quality

- **OOP Principles**: Encapsulation, inheritance, polymorphism
- **Type Hints**: All functions include type annotations
- **Documentation**: Comprehensive docstrings for all classes and methods
- **Testing**: Unit tests for key components
- **CI/CD**: Automated linting and testing via GitHub Actions

---

## 8. Next Steps

### Immediate (Task 3 - Current Focus)

1. **Complete Hypothesis Testing**:
   - Test risk differences across provinces (ANOVA/Kruskal-Wallis)
   - Test risk differences between zipcodes
   - Test margin differences between zipcodes
   - Test risk differences between genders (Mann-Whitney U)
   - Document all test results with p-values and interpretations

2. **Generate Additional Visualizations**:
   - Loss ratio by gender
   - Multi-dimensional loss ratio (Province Ã— VehicleType)
   - Zipcode risk analysis
   - Margin analysis by location
   - Hypothesis test results visualization

3. **Statistical Reporting**:
   - Summarize all hypothesis test results
   - Provide actionable insights from statistical analysis
   - Update report with findings

### Short-term (Task 4 - Next Phase)

1. **Linear Regression by Zipcode**:
   - Fit regression models for each zipcode
   - Evaluate model performance (RÂ², RMSE, MAE)
   - Identify best and worst performing zipcode models

2. **Premium Prediction Model**:
   - Feature engineering from all available dimensions
   - Train Random Forest and Gradient Boosting models
   - Evaluate and compare model performance
   - Analyze feature importance

3. **Model Deployment**:
   - Create model performance visualizations
   - Document model interpretability
   - Prepare model for production use

### Future Tasks

- Build interactive executive dashboard
- Generate comprehensive recommendations
- Present findings to stakeholders
- Implement pricing strategy adjustments

---

## 9. Expected Deliverables

| Deliverable | Status | Description |
|------------|--------|-------------|
| Data Pipeline | âœ… Completed | Automated data loading and preprocessing |
| EDA Framework | âœ… Completed | Comprehensive exploratory analysis classes |
| Initial Visualizations | âœ… Completed | 5 key visualizations generated |
| Statistical Analysis | ðŸ”„ In Progress | Hypothesis test results |
| Predictive Models | ðŸ“‹ Planned | Trained models for claims and premium prediction |
| Complete Visualization Suite | ðŸ”„ In Progress | 17+ visualizations (5 of 17 completed) |
| Executive Dashboard | ðŸ“‹ Planned | Interactive dashboard for stakeholders |
| Final Report | ðŸ”„ In Progress | Complete analysis with recommendations |

---

## 10. Key Metrics & KPIs

### Business Metrics

- **Overall Loss Ratio**: Calculated and monitored as primary KPI
- **Low-Risk Segment Size**: Identified through province and vehicle analysis
- **Risk Variation**: Quantified across geographic and vehicle dimensions
- **Temporal Trends**: Tracked over 18-month period

### Technical Metrics

- **Data Quality**: 1,000,098 records processed successfully
- **Visualization Coverage**: 5 of 17 planned visualizations completed (29%)
- **Code Quality**: OOP architecture with modular design
- **Reproducibility**: DVC integration for data version control
- **Test Coverage**: Unit tests for key components

---

## 11. Risk Factors & Considerations

1. **Data Quality**: Missing values handled, outliers identified and documented
2. **Temporal Changes**: Market conditions may have changed since 2015 data period
3. **Model Generalization**: Models will need validation on current data
4. **Regulatory Compliance**: Ensure pricing strategies comply with South African regulations
5. **Ethical Considerations**: Avoid discriminatory pricing practices

---

## 12. Conclusion

This project establishes a solid foundation for data-driven insurance risk analytics. Through comprehensive EDA and initial visualizations, we have:

- **Identified Key Risk Segments**: Provinces and vehicle types with varying risk profiles
- **Established Analysis Framework**: OOP architecture enabling scalable analysis
- **Generated Actionable Insights**: Visualizations supporting business decision-making
- **Created Reproducible Pipeline**: DVC integration ensures data version control

The visualization path provides clear communication of insights to both technical and business stakeholders. As we progress with hypothesis testing and predictive modeling, we will build upon these foundations to deliver comprehensive recommendations for premium optimization and marketing strategy.

**Project Status**: Task 1 & 2 Completed | Task 3 In Progress  
**Last Updated**: December 2025  
**Team**: AlphaCare Insurance Solutions Data Analytics Team  
**Data Records Analyzed**: 1,000,098

---

## Appendix: Visualization Files

All visualizations are saved in `reports/visualizations/`:

1. `01_portfolio_overview.png` - Portfolio Overview Dashboard
2. `03_loss_ratio_province.png` - Loss Ratio by Province
3. `04_loss_ratio_vehicle_type.png` - Loss Ratio by Vehicle Type
4. `07_temporal_trends.png` - Temporal Trends Analysis
5. `09_vehicle_make_analysis.png` - Vehicle Make Analysis

**Generation Script**: `scripts/generate_visualizations.py`
